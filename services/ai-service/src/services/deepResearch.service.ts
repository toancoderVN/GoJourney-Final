import { GoogleGenAI } from '@google/genai';
import dotenv from 'dotenv';
import { memoryService } from '../rag/memory.service';
import { FormattedMemoryContext } from '../rag/memory.types';

dotenv.config();

// Interface cho source v·ªõi c·∫£ title v√† URL
export interface SourceInfo {
  title: string;
  uri: string;
}

export interface DeepResearchStreamEvent {
  type: 'start' | 'thinking' | 'search_query' | 'content' | 'sources' | 'done' | 'error' | 'memory';
  content?: string;
  sources?: SourceInfo[];
  searchQueries?: string[];
  error?: string;
  memoriesUsed?: number;
}

export interface DeepResearchResult {
  content: string;
  thinkingContent: string;
  sources: SourceInfo[];
  searchQueries: string[];
  success: boolean;
  error?: string;
  memoriesUsed?: number;
}

export class DeepResearchService {
  private ai: GoogleGenAI;
  private readonly model = 'gemini-2.5-flash'; // Same as WebSearch

  private readonly baseSystemPrompt = `B·∫°n l√† GoJourney - chuy√™n gia nghi√™n c·ª©u du l·ªãch chuy√™n s√¢u.

NHI·ªÜM V·ª§ NGHI√äN C·ª®U S√ÇU:
- T√¨m ki·∫øm v√† cung c·∫•p th√¥ng tin v·ªÅ kh√°ch s·∫°n, ƒë·ªãa ƒëi·ªÉm du l·ªãch, nh√† h√†ng t·∫°i Vi·ªát Nam
- Lu√¥n c·ªë g·∫Øng t√¨m S·ªê ƒêI·ªÜN THO·∫†I li√™n h·ªá c·ªßa c√°c c∆° s·ªü kinh doanh n·∫øu c√≥ th·ªÉ
- T√¨m ki·∫øm nhi·ªÅu l·∫ßn v·ªõi c√°c g√≥c ƒë·ªô kh√°c nhau ƒë·ªÉ c√≥ th√¥ng tin to√†n di·ªán
- T·ªïng h·ª£p th√¥ng tin t·ª´ nhi·ªÅu ngu·ªìn ƒë√°ng tin c·∫≠y
- Cung c·∫•p ph√¢n t√≠ch chi ti·∫øt, kh√¥ng ch·ªâ li·ªát k√™ th√¥ng tin
- Cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ gi√° c·∫£, th·ªùi gian, v√† c√°c th√¥ng tin li√™n quan
- L√™n k·∫ø ho·∫°ch chi ti·∫øt v·ªÅ c√°c ho·∫°t ƒë·ªông, d·ªãch v·ª•, v√† th√¥ng tin li√™n quan n·∫øu ng∆∞·ªùi d√πng y√™u c·∫ßu
- H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn l·∫°i m·ªôt ch√∫t, nh∆∞ng v·∫´n ƒë·ªß √Ω ƒë·ªÉ ƒë·ª° t·ªën context

N·ªòI DUNG C·∫¶N ƒê∆ØA V√ÄO:
- Th√¥ng tin t·ªïng quan v√† l·ªãch s·ª≠ (n·∫øu c√≥)
- Chi ti·∫øt v·ªÅ ƒë·ªãa ƒëi·ªÉm, gi√° c·∫£, gi·ªù m·ªü c·ª≠a
- ƒê√°nh gi√° v√† nh·∫≠n x√©t t·ª´ du kh√°ch
- Tips v√† kinh nghi·ªám du l·ªãch th·ª±c t·∫ø
- S·ªë ƒëi·ªán tho·∫°i li√™n h·ªá khi c√≥ th·ªÉ
- So s√°nh c√°c l·ª±a ch·ªçn n·∫øu ph√π h·ª£p

ƒê·ªäNH D·∫†NG TR·∫¢ L·ªúI:
- S·ª≠ d·ª•ng Markdown v·ªõi heading (## ###) r√µ r√†ng
- D√πng bullet points (-) v√† s·ªë th·ª© t·ª± (1. 2. 3.) cho danh s√°ch
- In ƒë·∫≠m (**text**) cho th√¥ng tin quan tr·ªçng
- Chia th√†nh c√°c section logic, d·ªÖ ƒë·ªçc
- ƒê·ªô d√†i: Chi ti·∫øt, ƒë·∫ßy ƒë·ªß (t·ªëi thi·ªÉu 500 t·ª´)

NG√îN NG·ªÆ: Ti·∫øng Vi·ªát`;

  constructor() {
    const apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) {
      throw new Error('GEMINI_API_KEY kh√¥ng t·ªìn t·∫°i trong .env');
    }

    this.ai = new GoogleGenAI({ apiKey });
  }

  /**
   * Build system prompt with memory context if available
   */
  private buildSystemPrompt(memoryContext: FormattedMemoryContext): string {
    if (!memoryContext.hasMemories) {
      return this.baseSystemPrompt;
    }

    return `${this.baseSystemPrompt}

${memoryContext.formattedText}`;
  }

  /**
   * Extract sources from grounding metadata
   */
  private extractSources(metadata: any): SourceInfo[] {
    if (!metadata?.groundingChunks) return [];

    return metadata.groundingChunks
      .filter((chunk: any) => chunk.web)
      .map((chunk: any) => ({
        title: chunk.web?.title || 'Unknown',
        uri: chunk.web?.uri || '',
      }))
      .filter((source: SourceInfo) => source.uri);
  }

  /**
   * Stream Deep Research with memory injection
   * @param query - Research query
   * @param userId - Optional user ID for memory retrieval
   * @param sessionId - Optional session ID for memory storage
   */
  async *searchWithStream(
    query: string,
    userId?: string,
    sessionId?: string
  ): AsyncGenerator<DeepResearchStreamEvent> {
    try {
      console.log('üî¨ [DeepResearch] Starting deep research:', query);
      if (userId) {
        console.log('üë§ [DeepResearch] User ID:', userId);
      }

      yield { type: 'start' };

      // Step 1: Retrieve relevant memories if userId is provided
      let memoryContext: FormattedMemoryContext = {
        hasMemories: false,
        formattedText: '',
        memoriesUsed: 0,
      };

      if (userId) {
        try {
          const memories = await memoryService.retrieveRelevantMemories({
            userId,
            query,
            topK: 3,
            minSimilarity: 0.3,
          });

          if (memories.length > 0) {
            memoryContext = memoryService.formatMemoriesForPrompt(memories);
            console.log(`üìö [DeepResearch] Injecting ${memoryContext.memoriesUsed} memories`);

            // Emit memory event to inform frontend
            yield {
              type: 'memory',
              memoriesUsed: memoryContext.memoriesUsed,
            };
          }
        } catch (memoryError: any) {
          console.warn('‚ö†Ô∏è [DeepResearch] Memory retrieval failed:', memoryError.message);
          // Continue without memory - don't fail the research
        }
      }

      // Step 2: Build system prompt with memory context
      const systemPrompt = this.buildSystemPrompt(memoryContext);

      // Step 3: Execute research
      const responseStream = await this.ai.models.generateContentStream({
        model: this.model,
        contents: query,
        config: {
          systemInstruction: systemPrompt,
          tools: [{ googleSearch: {} }],

          // Try with thinkingBudget but WITHOUT includeThoughts
          thinkingConfig: {
            thinkingBudget: 512,
            includeThoughts: true, // Disabled - may conflict with googleSearch
          },
        },
      });

      let fullContent = '';
      let thinkingContent = '';
      let sources: SourceInfo[] = [];
      let searchQueries: string[] = [];

      for await (const chunk of responseStream) {
        // Handle thinking content (from thinkingBudget)
        if (chunk.candidates?.[0]?.content?.parts) {
          for (const part of chunk.candidates[0].content.parts) {
            // Check if this is a thought part
            if (part.thought) {
              const thoughtText = part.text || '';
              if (thoughtText) {
                thinkingContent += thoughtText;
                yield {
                  type: 'thinking',
                  content: thoughtText,
                };
              }
            }
          }
        }

        // Stream regular text content
        if (chunk.text) {
          fullContent += chunk.text;
          yield {
            type: 'content',
            content: chunk.text,
          };
        }

        // Extract grounding metadata
        const candidate = chunk.candidates?.[0];

        // Debug log to check grounding metadata
        if (candidate) {
          console.log('üîç [DeepResearch] Candidate metadata:', {
            hasGroundingMetadata: !!candidate.groundingMetadata,
            searchQueries: candidate.groundingMetadata?.webSearchQueries,
            chunksCount: candidate.groundingMetadata?.groundingChunks?.length || 0,
          });
        }

        if (candidate?.groundingMetadata) {
          const metadata = candidate.groundingMetadata;

          // Get search queries (show what AI is searching)
          if (metadata.webSearchQueries && metadata.webSearchQueries.length > 0) {
            const newQueries = metadata.webSearchQueries.filter(
              (q: string) => !searchQueries.includes(q)
            );
            if (newQueries.length > 0) {
              searchQueries.push(...newQueries);
              // Emit search query event
              for (const q of newQueries) {
                yield {
                  type: 'search_query',
                  content: `üîç ƒêang t√¨m ki·∫øm: "${q}"`,
                };
              }
            }
          }

          // Extract sources
          sources = this.extractSources(metadata);
        }
      }

      // Send sources at the end
      if (sources.length > 0 || searchQueries.length > 0) {
        yield {
          type: 'sources',
          sources,
          searchQueries,
        };
      }

      yield { type: 'done' };

      console.log('‚úÖ [DeepResearch] Completed. Content length:', fullContent.length);
      console.log('üß† [DeepResearch] Thinking length:', thinkingContent.length);
      console.log('üìö [DeepResearch] Sources:', sources.length);
      console.log('üîç [DeepResearch] Search queries:', searchQueries);

      // Step 4: Store research result as memory (async, don't wait)
      if (userId && fullContent.length > 100) {
        this.storeResearchMemory(userId, sessionId, query, fullContent).catch(err => {
          console.warn('‚ö†Ô∏è [DeepResearch] Failed to store memory:', err.message);
        });
      }

    } catch (error) {
      console.error('‚ùå [DeepResearch] Stream error:', error);
      yield {
        type: 'error',
        error: error instanceof Error ? error.message : 'Unknown error',
      };
    }
  }

  /**
   * Non-streaming Deep Research with memory injection
   * @param query - Research query
   * @param userId - Optional user ID for memory retrieval
   * @param sessionId - Optional session ID for memory storage
   */
  async search(
    query: string,
    userId?: string,
    sessionId?: string
  ): Promise<DeepResearchResult> {
    try {
      console.log('üî¨ [DeepResearch] Starting search:', query);

      // Step 1: Retrieve relevant memories if userId is provided
      let memoryContext: FormattedMemoryContext = {
        hasMemories: false,
        formattedText: '',
        memoriesUsed: 0,
      };

      if (userId) {
        try {
          const memories = await memoryService.retrieveRelevantMemories({
            userId,
            query,
            topK: 3,
            minSimilarity: 0.3,
          });

          if (memories.length > 0) {
            memoryContext = memoryService.formatMemoriesForPrompt(memories);
            console.log(`üìö [DeepResearch] Injecting ${memoryContext.memoriesUsed} memories`);
          }
        } catch (memoryError: any) {
          console.warn('‚ö†Ô∏è [DeepResearch] Memory retrieval failed:', memoryError.message);
        }
      }

      // Step 2: Build system prompt with memory context
      const systemPrompt = this.buildSystemPrompt(memoryContext);

      // Step 3: Execute research
      const response = await this.ai.models.generateContent({
        model: this.model,
        contents: query,
        config: {
          systemInstruction: systemPrompt,
          tools: [{ googleSearch: {} }],

          thinkingConfig: {
            thinkingBudget: 512,
            includeThoughts: true,
          },
        },
      });

      const content = response.text || '';
      let thinkingContent = '';
      let sources: SourceInfo[] = [];
      let searchQueries: string[] = [];

      // Extract thinking content
      if (response.candidates?.[0]?.content?.parts) {
        for (const part of response.candidates[0].content.parts) {
          if (part.thought && part.text) {
            thinkingContent += part.text;
          }
        }
      }

      // Extract grounding metadata
      const metadata = response.candidates?.[0]?.groundingMetadata;
      if (metadata) {
        if (metadata.webSearchQueries) {
          searchQueries = metadata.webSearchQueries;
        }
        sources = this.extractSources(metadata);
      }

      console.log('‚úÖ [DeepResearch] Search completed. Content length:', content.length);

      // Step 4: Store research result as memory (async, don't wait)
      if (userId && content.length > 100) {
        this.storeResearchMemory(userId, sessionId, query, content).catch(err => {
          console.warn('‚ö†Ô∏è [DeepResearch] Failed to store memory:', err.message);
        });
      }

      return {
        content,
        thinkingContent,
        sources,
        searchQueries,
        success: true,
        memoriesUsed: memoryContext.memoriesUsed,
      };

    } catch (error) {
      console.error('‚ùå [DeepResearch] Search error:', error);
      return {
        content: '',
        thinkingContent: '',
        sources: [],
        searchQueries: [],
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
      };
    }
  }

  /**
   * Store research result as memory (async helper)
   */
  private async storeResearchMemory(
    userId: string,
    sessionId: string | undefined,
    query: string,
    content: string
  ): Promise<void> {
    await memoryService.extractAndStoreFromConversation(
      userId,
      sessionId || 'unknown',
      query,
      content,
      'deep_research'
    );
    console.log('üíæ [DeepResearch] Research stored as memory');
  }
}