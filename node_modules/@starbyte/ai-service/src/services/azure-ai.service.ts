import axios from 'axios';
import { memoryService } from '../rag/memory.service';
import { FormattedMemoryContext } from '../rag/memory.types';

export interface ChatMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface ChatCompletionResponse {
  id: string;
  content: string;
  type: 'text' | 'trip_suggestion' | 'booking_info' | 'error';
  data?: any;
  suggestions?: string[];
  memoriesUsed?: number;
}

export class AzureAIService {
  private endpoint: string;
  private token: string;
  private modelName: string;
  private cache: Map<string, { response: ChatCompletionResponse; timestamp: number }> = new Map();
  private readonly CACHE_TTL = 300000; // 5 minutes cache

  private readonly baseSystemPromptVi = `B·∫°n l√† tr·ª£ l√Ω ƒë·∫°i l√Ω du l·ªãch AI cho StarByte Travel. H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn, th√¢n thi·ªán b·∫±ng ti·∫øng Vi·ªát.`;
  private readonly baseSystemPromptEn = `You are an AI travel assistant for StarByte Travel. Keep responses concise and friendly.`;

  constructor(endpoint: string, token: string, modelName: string) {
    this.endpoint = endpoint;
    this.token = token;
    this.modelName = modelName;
  }

  private getCacheKey(messages: ChatMessage[], language: string): string {
    const lastMessage = messages[messages.length - 1]?.content || '';
    return `${lastMessage.toLowerCase().trim()}_${language}`;
  }

  private getCachedResponse(cacheKey: string): ChatCompletionResponse | null {
    const cached = this.cache.get(cacheKey);
    if (cached && (Date.now() - cached.timestamp) < this.CACHE_TTL) {
      console.log('Returning cached response for:', cacheKey.substring(0, 50));
      return cached.response;
    }
    return null;
  }

  private setCachedResponse(cacheKey: string, response: ChatCompletionResponse): void {
    this.cache.set(cacheKey, { response, timestamp: Date.now() });

    // Clean old cache entries
    if (this.cache.size > 100) {
      const now = Date.now();
      for (const [key, value] of this.cache.entries()) {
        if (now - value.timestamp > this.CACHE_TTL) {
          this.cache.delete(key);
        }
      }
    }
  }

  /**
   * Build system prompt with memory context if available
   */
  private buildSystemPrompt(
    language: string,
    customPrompt?: string,
    memoryContext?: FormattedMemoryContext
  ): string {
    // Use custom prompt if provided, otherwise use default
    let basePrompt = customPrompt || (language === 'vi'
      ? this.baseSystemPromptVi
      : this.baseSystemPromptEn);

    // Append memory context if available
    if (memoryContext?.hasMemories) {
      basePrompt = `${basePrompt}\n\n${memoryContext.formattedText}`;
    }

    return basePrompt;
  }

  /**
   * Generate chat response with optional memory integration
   * @param messages - Chat messages
   * @param language - Language code
   * @param systemPrompt - Optional custom system prompt
   * @param userId - Optional user ID for memory retrieval
   * @param sessionId - Optional session ID for memory storage
   */
  async generateChatResponse(
    messages: ChatMessage[],
    language: string = 'en',
    systemPrompt?: string,
    userId?: string,
    sessionId?: string
  ): Promise<ChatCompletionResponse> {
    // Early guards: ensure token and messages exist to avoid sending empty auth header
    if (!this.token || this.token.trim() === '') {
      console.error('Missing AI token for AzureAIService. Aborting request.');
      return {
        id: Date.now().toString(),
        content: language === 'vi'
          ? 'Thi·∫øu c·∫•u h√¨nh x√°c th·ª±c AI. Vui l√≤ng li√™n h·ªá qu·∫£n tr·ªã vi√™n.'
          : 'Missing AI auth token. Please contact the administrator.',
        type: 'error'
      };
    }

    if (!messages || messages.length === 0) {
      console.error('generateChatResponse called with empty messages array');
      return {
        id: Date.now().toString(),
        content: language === 'vi'
          ? 'Kh√¥ng c√≥ n·ªôi dung cu·ªôc h·ªôi tho·∫°i ƒë·ªÉ x·ª≠ l√Ω.'
          : 'No conversation content provided.',
        type: 'error'
      };
    }

    try {
      const lastContent = messages[messages.length - 1]?.content;
      console.log('Generating chat response for:', lastContent ? lastContent.substring(0, 100) : '(no content)');
      if (userId) {
        console.log('üë§ [AzureAI] User ID:', userId);
      }

      // Check cache first for common queries if NO custom system prompt (custom prompts imply unique context)
      // Also skip cache if userId is provided (memory-enabled queries should be fresh)
      let cacheKey = '';
      let cachedResponse = null;

      if (!systemPrompt && !userId) {
        cacheKey = this.getCacheKey(messages, language);
        cachedResponse = this.getCachedResponse(cacheKey);
      }

      if (cachedResponse) {
        return cachedResponse;
      }

      // Step 1: Retrieve relevant memories if userId is provided
      let memoryContext: FormattedMemoryContext = {
        hasMemories: false,
        formattedText: '',
        memoriesUsed: 0,
      };

      const userQuery = messages[messages.length - 1]?.content || '';

      if (userId && userQuery.length > 5) {
        try {
          const memories = await memoryService.retrieveRelevantMemories({
            userId,
            query: userQuery,
            topK: 3,
            minSimilarity: 0.3,
          });

          if (memories.length > 0) {
            memoryContext = memoryService.formatMemoriesForPrompt(memories);
            console.log(`üìö [AzureAI] Injecting ${memoryContext.memoriesUsed} memories`);
          }
        } catch (memoryError: any) {
          console.warn('‚ö†Ô∏è [AzureAI] Memory retrieval failed:', memoryError.message);
        }
      }

      // Step 2: Build system prompt with memory context
      const finalSystemPrompt = this.buildSystemPrompt(language, systemPrompt, memoryContext);

      const systemMessage: ChatMessage = {
        role: 'system',
        content: finalSystemPrompt
      };

      const fullMessages = [systemMessage, ...messages];

      // Step 3: Call GitHub Models API directly with optimized settings
      console.log('[AzureAI] üîÑ Sending request to GitHub Models API...');
      console.log('[AzureAI] Model:', this.modelName);
      console.log('[AzureAI] Token present:', !!this.token, 'tokenPrefix:', this.token ? this.token.slice(0, 8) + '...' : '(none)');
      console.log('[AzureAI] Messages count:', fullMessages.length);

      const response = await axios.post('https://models.github.ai/inference/chat/completions', {
        model: this.modelName,
        messages: fullMessages.map(msg => ({
          role: msg.role,
          content: msg.content
        })),
        temperature: 0.3, // Lower for faster, more focused responses
        max_tokens: 500,  // Reduced for faster generation
        stream: false,    // Disable streaming for simpler handling
        top_p: 0.9       // Optimize for speed
      }, {
        headers: {
          'Accept': 'application/vnd.github+json',
          'Authorization': `Bearer ${this.token}`,
          'X-GitHub-Api-Version': '2022-11-28',
          'Content-Type': 'application/json'
        },
        timeout: 15000    // Reduced timeout to 15 seconds
      });

      console.log('[AzureAI] ‚úÖ Response received from GitHub Models API');
      console.log('[AzureAI] Status:', response.status);

      const content = response.data.choices?.[0]?.message?.content || '';
      console.log('[AzureAI] Content received:', content.substring(0, 100) + '...');

      // Classify response type based on content
      const responseType = this.classifyResponseType(content);

      // Generate suggestions based on content
      const suggestions = this.generateSuggestions(content, language);

      const result: ChatCompletionResponse = {
        id: Date.now().toString() + Math.random().toString(36).substr(2, 9),
        content,
        type: responseType,
        suggestions,
        memoriesUsed: memoryContext.memoriesUsed,
      };

      console.log('[AzureAI] ‚úÖ Result prepared, type:', responseType);

      // Cache the result for future use (only if no userId)
      if (!userId && cacheKey) {
        this.setCachedResponse(cacheKey, result);
      }

      // Step 4: Store conversation as memory (async, don't wait)
      if (userId && content.length > 50) {
        this.storeChatMemory(userId, sessionId, userQuery, content).catch(err => {
          console.warn('‚ö†Ô∏è [AzureAI] Failed to store memory:', err.message);
        });
      }

      console.log('[AzureAI] üéâ All done! Returning result');
      return result;

    } catch (error: any) {
      console.error('‚ùå [AzureAI] Service Error:', error.message);
      
      // Log response details if available (for 403, 401, etc.)
      if (error.response) {
        console.error('[AzureAI] ‚ùå HTTP Status:', error.response.status);
        console.error('[AzureAI] ‚ùå Response Headers:', error.response.headers);
        console.error('[AzureAI] ‚ùå Response Data:', error.response.data);
        
        if (error.response.status === 403) {
          console.error('[AzureAI] üö® 403 Forbidden - Token may lack required scopes or API access is restricted');
        } else if (error.response.status === 401) {
          console.error('[AzureAI] üö® 401 Unauthorized - Token invalid/expired');
        }
      }

      // Fallback response
      const fallbackContent = language === 'vi'
        ? 'Xin l·ªói, t√¥i ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t. Vui l√≤ng th·ª≠ l·∫°i sau √≠t ph√∫t.'
        : 'Sorry, I\'m experiencing technical difficulties. Please try again in a few minutes.';

      return {
        id: Date.now().toString(),
        content: fallbackContent,
        type: 'error'
      };
    }
  }

  /**
   * Store chat conversation as memory (async helper)
   */
  private async storeChatMemory(
    userId: string,
    sessionId: string | undefined,
    query: string,
    content: string
  ): Promise<void> {
    await memoryService.extractAndStoreFromConversation(
      userId,
      sessionId || 'unknown',
      query,
      content,
      'chat'
    );
    console.log('üíæ [AzureAI] Chat stored as memory');
  }

  private classifyResponseType(content: string): 'text' | 'trip_suggestion' | 'booking_info' | 'error' {
    const lowerContent = content.toLowerCase();

    if (lowerContent.includes('itinerary') || lowerContent.includes('destination') ||
      lowerContent.includes('l·ªãch tr√¨nh') || lowerContent.includes('ƒëi·ªÉm ƒë·∫øn')) {
      return 'trip_suggestion';
    }

    if (lowerContent.includes('booking') || lowerContent.includes('reservation') ||
      lowerContent.includes('ƒë·∫∑t ch·ªó') || lowerContent.includes('ƒë·∫∑t v√©')) {
      return 'booking_info';
    }

    return 'text';
  }

  private generateSuggestions(content: string, language: string): string[] {
    const suggestions: string[] = [];
    const lowerContent = content.toLowerCase();

    if (language === 'vi') {
      if (lowerContent.includes('du l·ªãch') || lowerContent.includes('chuy·∫øn ƒëi')) {
        suggestions.push('T√¥i mu·ªën xem g·ª£i √Ω ƒëi·ªÉm ƒë·∫øn');
        suggestions.push('H√£y gi√∫p t√¥i l·∫≠p k·∫ø ho·∫°ch chi ti·∫øt');
        suggestions.push('Ng√¢n s√°ch kho·∫£ng bao nhi√™u?');
      }

      if (lowerContent.includes('m√°y bay') || lowerContent.includes('v√©')) {
        suggestions.push('T√¨m v√© m√°y bay gi√° r·∫ª');
        suggestions.push('Ki·ªÉm tra l·ªãch bay');
        suggestions.push('Th·ªß t·ª•c check-in');
      }

      if (lowerContent.includes('kh√°ch s·∫°n')) {
        suggestions.push('T√¨m kh√°ch s·∫°n g·∫ßn ƒë√¢y');
        suggestions.push('So s√°nh gi√° ph√≤ng');
        suggestions.push('ƒê√°nh gi√° kh√°ch s·∫°n');
      }
    } else {
      if (lowerContent.includes('travel') || lowerContent.includes('trip')) {
        suggestions.push('Show me destination recommendations');
        suggestions.push('Help me plan detailed itinerary');
        suggestions.push('What\'s the budget estimate?');
      }

      if (lowerContent.includes('flight') || lowerContent.includes('airline')) {
        suggestions.push('Find cheap flights');
        suggestions.push('Check flight schedules');
        suggestions.push('Online check-in process');
      }

      if (lowerContent.includes('hotel')) {
        suggestions.push('Find nearby hotels');
        suggestions.push('Compare room prices');
        suggestions.push('Hotel reviews');
      }
    }

    return suggestions.slice(0, 3); // Limit to 3 suggestions
  }

  async executeQuickAction(
    actionId: string,
    data?: any,
    language: string = 'en',
    userId?: string,
    sessionId?: string
  ): Promise<ChatCompletionResponse> {
    let userQuery = '';

    switch (actionId) {
      case 'plan-trip':
        userQuery = language === 'vi'
          ? `T√¥i mu·ªën l·∫≠p k·∫ø ho·∫°ch cho m·ªôt chuy·∫øn du l·ªãch${data?.destination ? ` ƒë·∫øn ${data.destination}` : ''}. H√£y gi√∫p t√¥i v·ªõi c√°c b∆∞·ªõc c·∫ßn thi·∫øt.`
          : `I want to plan a trip${data?.destination ? ` to ${data.destination}` : ''}. Please help me with the necessary steps.`;
        break;

      case 'find-destination':
        userQuery = language === 'vi'
          ? 'H√£y g·ª£i √Ω cho t√¥i m·ªôt s·ªë ƒëi·ªÉm ƒë·∫øn du l·ªãch th√∫ v·ªã d·ª±a tr√™n xu h∆∞·ªõng hi·ªán t·∫°i.'
          : 'Please suggest some interesting travel destinations based on current trends.';
        break;

      case 'check-booking':
        userQuery = language === 'vi'
          ? 'T√¥i mu·ªën ki·ªÉm tra th√¥ng tin ƒë·∫∑t v√© v√† l·ªãch tr√¨nh c·ªßa m√¨nh.'
          : 'I want to check my booking information and itinerary.';
        break;

      default:
        userQuery = language === 'vi'
          ? 'T√¥i c·∫ßn h·ªó tr·ª£ v·ªÅ d·ªãch v·ª• du l·ªãch.'
          : 'I need assistance with travel services.';
    }

    const messages: ChatMessage[] = [
      { role: 'user', content: userQuery }
    ];

    return await this.generateChatResponse(messages, language, undefined, userId, sessionId);
  }
}
