import axios from 'axios';
import { memoryService } from '../rag/memory.service';
export class AzureAIService {
    endpoint;
    token;
    modelName;
    cache = new Map();
    CACHE_TTL = 300000; // 5 minutes cache
    baseSystemPromptVi = `B·∫°n l√† tr·ª£ l√Ω ƒë·∫°i l√Ω du l·ªãch AI cho StarByte Travel. H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn, th√¢n thi·ªán b·∫±ng ti·∫øng Vi·ªát.`;
    baseSystemPromptEn = `You are an AI travel assistant for StarByte Travel. Keep responses concise and friendly.`;
    constructor(endpoint, token, modelName) {
        this.endpoint = endpoint;
        this.token = token;
        this.modelName = modelName;
    }
    getCacheKey(messages, language) {
        const lastMessage = messages[messages.length - 1]?.content || '';
        return `${lastMessage.toLowerCase().trim()}_${language}`;
    }
    getCachedResponse(cacheKey) {
        const cached = this.cache.get(cacheKey);
        if (cached && (Date.now() - cached.timestamp) < this.CACHE_TTL) {
            console.log('Returning cached response for:', cacheKey.substring(0, 50));
            return cached.response;
        }
        return null;
    }
    setCachedResponse(cacheKey, response) {
        this.cache.set(cacheKey, { response, timestamp: Date.now() });
        // Clean old cache entries
        if (this.cache.size > 100) {
            const now = Date.now();
            for (const [key, value] of this.cache.entries()) {
                if (now - value.timestamp > this.CACHE_TTL) {
                    this.cache.delete(key);
                }
            }
        }
    }
    /**
     * Build system prompt with memory context if available
     */
    buildSystemPrompt(language, customPrompt, memoryContext) {
        // Use custom prompt if provided, otherwise use default
        let basePrompt = customPrompt || (language === 'vi'
            ? this.baseSystemPromptVi
            : this.baseSystemPromptEn);
        // Append memory context if available
        if (memoryContext?.hasMemories) {
            basePrompt = `${basePrompt}\n\n${memoryContext.formattedText}`;
        }
        return basePrompt;
    }
    /**
     * Generate chat response with optional memory integration
     * @param messages - Chat messages
     * @param language - Language code
     * @param systemPrompt - Optional custom system prompt
     * @param userId - Optional user ID for memory retrieval
     * @param sessionId - Optional session ID for memory storage
     */
    async generateChatResponse(messages, language = 'en', systemPrompt, userId, sessionId) {
        try {
            console.log('Generating chat response for:', messages[messages.length - 1]?.content?.substring(0, 100));
            if (userId) {
                console.log('üë§ [AzureAI] User ID:', userId);
            }
            // Check cache first for common queries if NO custom system prompt (custom prompts imply unique context)
            // Also skip cache if userId is provided (memory-enabled queries should be fresh)
            let cacheKey = '';
            let cachedResponse = null;
            if (!systemPrompt && !userId) {
                cacheKey = this.getCacheKey(messages, language);
                cachedResponse = this.getCachedResponse(cacheKey);
            }
            if (cachedResponse) {
                return cachedResponse;
            }
            // Step 1: Retrieve relevant memories if userId is provided
            let memoryContext = {
                hasMemories: false,
                formattedText: '',
                memoriesUsed: 0,
            };
            const userQuery = messages[messages.length - 1]?.content || '';
            if (userId && userQuery.length > 5) {
                try {
                    const memories = await memoryService.retrieveRelevantMemories({
                        userId,
                        query: userQuery,
                        topK: 3,
                        minSimilarity: 0.3,
                    });
                    if (memories.length > 0) {
                        memoryContext = memoryService.formatMemoriesForPrompt(memories);
                        console.log(`üìö [AzureAI] Injecting ${memoryContext.memoriesUsed} memories`);
                    }
                }
                catch (memoryError) {
                    console.warn('‚ö†Ô∏è [AzureAI] Memory retrieval failed:', memoryError.message);
                }
            }
            // Step 2: Build system prompt with memory context
            const finalSystemPrompt = this.buildSystemPrompt(language, systemPrompt, memoryContext);
            const systemMessage = {
                role: 'system',
                content: finalSystemPrompt
            };
            const fullMessages = [systemMessage, ...messages];
            // Step 3: Call GitHub Models API directly with optimized settings
            const response = await axios.post('https://models.github.ai/inference/chat/completions', {
                model: this.modelName,
                messages: fullMessages.map(msg => ({
                    role: msg.role,
                    content: msg.content
                })),
                temperature: 0.3, // Lower for faster, more focused responses
                max_tokens: 500, // Reduced for faster generation
                stream: false, // Disable streaming for simpler handling
                top_p: 0.9 // Optimize for speed
            }, {
                headers: {
                    'Accept': 'application/vnd.github+json',
                    'Authorization': `Bearer ${this.token}`,
                    'X-GitHub-Api-Version': '2022-11-28',
                    'Content-Type': 'application/json'
                },
                timeout: 15000 // Reduced timeout to 15 seconds
            });
            const content = response.data.choices?.[0]?.message?.content || '';
            // Classify response type based on content
            const responseType = this.classifyResponseType(content);
            // Generate suggestions based on content
            const suggestions = this.generateSuggestions(content, language);
            const result = {
                id: Date.now().toString() + Math.random().toString(36).substr(2, 9),
                content,
                type: responseType,
                suggestions,
                memoriesUsed: memoryContext.memoriesUsed,
            };
            // Cache the result for future use (only if no userId)
            if (!userId && cacheKey) {
                this.setCachedResponse(cacheKey, result);
            }
            // Step 4: Store conversation as memory (async, don't wait)
            if (userId && content.length > 50) {
                this.storeChatMemory(userId, sessionId, userQuery, content).catch(err => {
                    console.warn('‚ö†Ô∏è [AzureAI] Failed to store memory:', err.message);
                });
            }
            return result;
        }
        catch (error) {
            console.error('Azure AI Service Error:', error);
            // Fallback response
            const fallbackContent = language === 'vi'
                ? 'Xin l·ªói, t√¥i ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t. Vui l√≤ng th·ª≠ l·∫°i sau √≠t ph√∫t.'
                : 'Sorry, I\'m experiencing technical difficulties. Please try again in a few minutes.';
            return {
                id: Date.now().toString(),
                content: fallbackContent,
                type: 'error'
            };
        }
    }
    /**
     * Store chat conversation as memory (async helper)
     */
    async storeChatMemory(userId, sessionId, query, content) {
        await memoryService.extractAndStoreFromConversation(userId, sessionId || 'unknown', query, content, 'chat');
        console.log('üíæ [AzureAI] Chat stored as memory');
    }
    classifyResponseType(content) {
        const lowerContent = content.toLowerCase();
        if (lowerContent.includes('itinerary') || lowerContent.includes('destination') ||
            lowerContent.includes('l·ªãch tr√¨nh') || lowerContent.includes('ƒëi·ªÉm ƒë·∫øn')) {
            return 'trip_suggestion';
        }
        if (lowerContent.includes('booking') || lowerContent.includes('reservation') ||
            lowerContent.includes('ƒë·∫∑t ch·ªó') || lowerContent.includes('ƒë·∫∑t v√©')) {
            return 'booking_info';
        }
        return 'text';
    }
    generateSuggestions(content, language) {
        const suggestions = [];
        const lowerContent = content.toLowerCase();
        if (language === 'vi') {
            if (lowerContent.includes('du l·ªãch') || lowerContent.includes('chuy·∫øn ƒëi')) {
                suggestions.push('T√¥i mu·ªën xem g·ª£i √Ω ƒëi·ªÉm ƒë·∫øn');
                suggestions.push('H√£y gi√∫p t√¥i l·∫≠p k·∫ø ho·∫°ch chi ti·∫øt');
                suggestions.push('Ng√¢n s√°ch kho·∫£ng bao nhi√™u?');
            }
            if (lowerContent.includes('m√°y bay') || lowerContent.includes('v√©')) {
                suggestions.push('T√¨m v√© m√°y bay gi√° r·∫ª');
                suggestions.push('Ki·ªÉm tra l·ªãch bay');
                suggestions.push('Th·ªß t·ª•c check-in');
            }
            if (lowerContent.includes('kh√°ch s·∫°n')) {
                suggestions.push('T√¨m kh√°ch s·∫°n g·∫ßn ƒë√¢y');
                suggestions.push('So s√°nh gi√° ph√≤ng');
                suggestions.push('ƒê√°nh gi√° kh√°ch s·∫°n');
            }
        }
        else {
            if (lowerContent.includes('travel') || lowerContent.includes('trip')) {
                suggestions.push('Show me destination recommendations');
                suggestions.push('Help me plan detailed itinerary');
                suggestions.push('What\'s the budget estimate?');
            }
            if (lowerContent.includes('flight') || lowerContent.includes('airline')) {
                suggestions.push('Find cheap flights');
                suggestions.push('Check flight schedules');
                suggestions.push('Online check-in process');
            }
            if (lowerContent.includes('hotel')) {
                suggestions.push('Find nearby hotels');
                suggestions.push('Compare room prices');
                suggestions.push('Hotel reviews');
            }
        }
        return suggestions.slice(0, 3); // Limit to 3 suggestions
    }
    async executeQuickAction(actionId, data, language = 'en', userId, sessionId) {
        let userQuery = '';
        switch (actionId) {
            case 'plan-trip':
                userQuery = language === 'vi'
                    ? `T√¥i mu·ªën l·∫≠p k·∫ø ho·∫°ch cho m·ªôt chuy·∫øn du l·ªãch${data?.destination ? ` ƒë·∫øn ${data.destination}` : ''}. H√£y gi√∫p t√¥i v·ªõi c√°c b∆∞·ªõc c·∫ßn thi·∫øt.`
                    : `I want to plan a trip${data?.destination ? ` to ${data.destination}` : ''}. Please help me with the necessary steps.`;
                break;
            case 'find-destination':
                userQuery = language === 'vi'
                    ? 'H√£y g·ª£i √Ω cho t√¥i m·ªôt s·ªë ƒëi·ªÉm ƒë·∫øn du l·ªãch th√∫ v·ªã d·ª±a tr√™n xu h∆∞·ªõng hi·ªán t·∫°i.'
                    : 'Please suggest some interesting travel destinations based on current trends.';
                break;
            case 'check-booking':
                userQuery = language === 'vi'
                    ? 'T√¥i mu·ªën ki·ªÉm tra th√¥ng tin ƒë·∫∑t v√© v√† l·ªãch tr√¨nh c·ªßa m√¨nh.'
                    : 'I want to check my booking information and itinerary.';
                break;
            default:
                userQuery = language === 'vi'
                    ? 'T√¥i c·∫ßn h·ªó tr·ª£ v·ªÅ d·ªãch v·ª• du l·ªãch.'
                    : 'I need assistance with travel services.';
        }
        const messages = [
            { role: 'user', content: userQuery }
        ];
        return await this.generateChatResponse(messages, language, undefined, userId, sessionId);
    }
}
//# sourceMappingURL=azure-ai.service.js.map